{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ProblemStatement4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W2ZHyExB5aUI"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('/content/drive/MyDrive/Meta Files/train')"
      ],
      "metadata": {
        "id": "7lBE6qVE5knl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def random_files():\n",
        "  local_files_location={} # local dictionary to this function, key: name of file, value: location of file\n",
        "  local_files=[]  #local list to this function, names of all files are stored in this list\n",
        "  i=0\n",
        "  for r,d,f in os.walk(r'/content/drive/MyDrive/Meta Files/train'):\n",
        "    for file in f:\n",
        "      local_files_location[file]=os.path.join(r,file)\n",
        "      local_files.append(file)\n",
        "      i=i+1\n",
        "    if (i==10000):\n",
        "      break\n",
        "  return local_files_location, local_files"
      ],
      "metadata": {
        "id": "BTyp6MK16trc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def num_of_words_and_unique_words(fname):\n",
        "  with open(fname,'r') as file:\n",
        "    text = file.read()\n",
        "    #cleaning\n",
        "    text = text.lower()\n",
        "    words = text.split()\n",
        "    words = [word.strip('.,!;()[]') for word in words]\n",
        "    words = [word.replace(\"'s\", '') for word in words]\n",
        "\n",
        "    #finding unique\n",
        "    unique = []\n",
        "    for word in words:\n",
        "        if word not in unique:\n",
        "            unique.append(word)\n",
        "  return len(words), len(unique)"
      ],
      "metadata": {
        "id": "gmxxDiK69d6h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_uppercase_letters(fname):\n",
        "  with open(fname) as countletter:\n",
        "    count = 0\n",
        "    text = countletter.read()\n",
        "    for character in text:\n",
        "      if character.isupper():\n",
        "        count += 1\n",
        "  return count"
      ],
      "metadata": {
        "id": "OE2EbORo-2i2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_lowercase_letters(fname):\n",
        "  with open(fname) as countletter:\n",
        "    count = 0\n",
        "    text = countletter.read()\n",
        "    for character in text:\n",
        "      if character.islower():\n",
        "        count += 1\n",
        "  return count"
      ],
      "metadata": {
        "id": "QLW3SKwx_ob8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_camelcase_words(fname):\n",
        "  count = 0\n",
        "  with open(fname) as file:\n",
        "    data=file.read()\n",
        "    for string in data:\n",
        "      for i in range(1, len(string) - 1):\n",
        "        if (string[i].isupper()):\n",
        "          count += 1\n",
        "          break\n",
        "  return count"
      ],
      "metadata": {
        "id": "Ej0kQrSkA-QW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_character(fname):\n",
        "  count=0\n",
        "  with open(fname) as file:\n",
        "    data=file.read()\n",
        "    for string in data:\n",
        "      count+=len(string)\n",
        "  return count"
      ],
      "metadata": {
        "id": "ZD29Z1EaD0wq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_numeric_character(fname):\n",
        "  count=0\n",
        "  with open(fname) as file:\n",
        "    data=file.read()\n",
        "    for string in data:\n",
        "      words=list(string.split())\n",
        "      for word in words:\n",
        "        if (word.isnumeric()):\n",
        "          count+=1\n",
        "  return count\n",
        "\n"
      ],
      "metadata": {
        "id": "B1pM37sYEmeQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_nonalphanumeric_character(fname):\n",
        "  count1=0\n",
        "  count2=0\n",
        "  with open(fname) as file:\n",
        "    data=file.read()\n",
        "    for string in data:\n",
        "      words=list(string.split())\n",
        "      for word in words:\n",
        "        if (word.isnumeric()):\n",
        "          count1 += 1\n",
        "        elif (word.isalpha()):\n",
        "          count1 += 1\n",
        "        else:\n",
        "          count1 = count1\n",
        "    for string in data:\n",
        "      count2= count2 + len(string)\n",
        "  return count2 - count1"
      ],
      "metadata": {
        "id": "6BMboYWOGwUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_files():\n",
        "  files_location, files = random_files()\n",
        "  file_name = []\n",
        "  total_words = []\n",
        "  total_unique_words = []\n",
        "  uppercase_words = []\n",
        "  lowercase_words = []\n",
        "  camelcase_words = []\n",
        "  total_characters = []\n",
        "  numeric_characters = []\n",
        "  nonalphanumeric_characters = []\n",
        "  for file in files:\n",
        "    file_name.append(file)\n",
        "    fname=files_location[file]\n",
        "    t_w, t_u_w = num_of_words_and_unique_words(fname)\n",
        "    total_words.append(t_w)\n",
        "    total_unique_words.append(t_u_w)\n",
        "    uppercase_words.append(count_uppercase_letters(fname))\n",
        "    lowercase_words.append(count_lowercase_letters(fname))\n",
        "    camelcase_words.append(count_camelcase_words(fname))\n",
        "    total_characters.append(count_character(fname))\n",
        "    numeric_characters.append(count_numeric_character(fname))\n",
        "    nonalphanumeric_characters.append(count_nonalphanumeric_character(fname))\n",
        "  dict = {'File_name': file_name, 'num_words': total_words, 'num_unique_words': total_unique_words, 'num_cap_words': uppercase_words, 'num_camel_case_words': camelcase_words, 'num_lower_case_letters': lowercase_words, 'num_characters': total_characters, 'num_num_characters': numeric_characters, 'num_non_alpha_numeric_chars': nonalphanumeric_characters}\n",
        "  df = pd.DataFrame(dict)\n",
        "  df.to_csv('output.csv')"
      ],
      "metadata": {
        "id": "ot1k-kR2bYKS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "process_files()"
      ],
      "metadata": {
        "id": "Qe5P0yTSc9NX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}